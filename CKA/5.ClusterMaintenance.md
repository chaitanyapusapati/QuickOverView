# OS Upgrades
- Take me to [Video Tutorial](https://kodekloud.com/courses/539883/lectures/9808229)
  
Say you have a cluster with a few nodes and pods serving applications. What happens when one of these nodes go down. Of course the pods on them are not accessible. Now depending upon how you deployed those PODs your users may be impacted.

For example, since you have multiple replicas of the blue pod, the users accessing the blue application are not impacted as they are being served through the other blue pod that's on line. However users accessing the green pod, are impacted as that was the only pod running the green application. Now what does kubernetes do in this case? If the node came back online immediately, then the kubectl process starts and the pods come back onine. `*However, if the node was down for more than 5 minutes, then the pods are terminated from that node. Well, kubernetes considers them as dead.*` 

If the PODs were part of a replicaset then they are recreated on other nodes. The time it waits for a pod to come back online is known as the `pod eviction timeout` and is set on the controller manager with a default value of five minutes. So whenever a node goes offline, the master node waits for upto 5 minutes before considering the node dead. When the node comes back on line after the pod eviction timeout it comes up blank without any pods scheduled on it. Since the blue pod was part of a replicaset, it had a new pod created On another node. However since the green pod was not part of the replica set it's just gone. 

Thus if you have maintenance tasks to be performed on a node, if you know that the workloads running on the Node have other replicas and if it's okay that they go down for a short period of time. And if you're sure the node will come back on line within five minutes you can make a quick upgrade and reboot. However you do not for sure know if a node is going to be back on line in five minutes. Well you cannot for sure say it is going to be back at all. So there is a safer way to do it. You can purposefully drain the node of all the workloads so that the workloads are moved to other nodes in the cluster. Well technically they are not moved. `When you drain the node the pods are gracefully terminated from the node that they're on and recreated on another. The node is also cordoned or marked as unschedulable.` Meaning no pods can be scheduled on this node until you specifically remove the restriction.

Now that the pods are safe on the others nodes, you can reboot the first node. When it comes back online it is still unschedulable. You then need to uncordon it, so that pods can be scheduled on it again. Now, remember the pods that were moved to the other nodes, donâ€™t automatically fall back. If any of those pods where deleted or if new pods were created in the cluster, Then they would be created on this node. Apart from drain and uncordon, there is also another command called `cordon`. Cordon simply marks a node unschedulable. Unlike drain it does not terminate or move the pods on an existing node.It simply makes sure that new pods are not scheduled on that node.

- You can purposefully **`drain`** the node of all the workloads so that the workloads are moved to other nodes.
```
$ kubectl drain <node_name>
$ kubectl drain node01
$ kubectl drain node01 --ignore-daemonsets
```
The node is also cordoned or marked as unschedulable.
When the node is back online after a maintenance, it is still unschedulable. You then need to uncordon it.
```
$ kubectl uncordon <node_name>
```
- There is also another command called cordon. Cordon simply marks a node unschedulable. Unlike drain it does not terminate or move the pods on an existing node.
```
$ kubectl cordon <node_name>
```

# Kubernetes Software Versions
- Take me to [Video Tutorial](https://kodekloud.com/courses/539883/lectures/9808230)
  
#### We can see the kubernetess version that we installed
```
$ kubectl get nodes
```

#### Let's take a closer look at the version number
- It consists of 3 parts
  - First is the major version
  - Second is the minor version
  - Finally, the patch version
  
  
#### Kubernetes follows a standard software release versioning procedure
- You can find all kubernetes releases at https://github.com/kubernetes/kubernetes/releases

  
#### Downloaded package has all the kubernetes components in it except **`ETCD Cluster`** and **`CoreDNS`** as they are seperate projects.


# Cluster Upgrade Introduction
  - Take me to [Video Tutorial](https://kodekloud.com/courses/539883/lectures/9808227)
  
#### Is it mandatory for all of the kubernetes components to have the same versions?
- No, The components can be at different release versions.
  
#### At any time, kubernetes supports only up to the recent 3 minor versions
- The recommended approach is to upgrade one minor version at a time.
  
  
#### Options to upgrade k8s cluster
 
  
## Upgrading a Cluster
- Upgrading a cluster involves 2 major steps
  
#### There are different strategies that are available to upgrade the worker nodes
- One is to upgrade all at once. But then your pods will be down and users will not be able to access the applications.

- Second one is to upgrade one node at a time. 

- Third one would be to add new nodes to the cluster

  
## kubeadm - Upgrade master node
- kubeadm has an upgrade command that helps in upgrading clusters.
  ```
  $ kubeadm upgrade plan
  ```

  
- Upgrade kubeadm from v1.11 to v1.12
  ```
  $ apt-get upgrade -y kubeadm=1.12.0-00
  ```
- Upgrade the cluster
  ```
  $ kubeadm upgrade apply v1.12.0
  ```
- If you run the 'kubectl get nodes' command, you will see the older version. This is because in the output of the command it is showing the versions of kubelets on each of these nodes registered with the API Server and not the version of API Server itself  
  ```
  $ kubectl get nodes
  ```
  
  
- Upgrade 'kubelet' on the master node
  ```
  $ apt-get upgrade kubelet=1.12.0-00
  ```
- Restart the kubelet
  ```
  $ systemctl restart kubelet
  ```
- Run 'kubectl get nodes' to verify
  ```
  $ kubectl get nodes
  ```
  

 
## kubeadm - Upgrade worker nodes
  
- From master node, run 'kubectl drain' command to move the workloads to other nodes
  ```
  $ kubectl drain node-1
  ```
- Upgrade kubeadm and kubelet packages
  ```
  $ apt-get upgrade -y kubeadm=1.12.0-00
  $ apt-get upgrade -y kubelet=1.12.0-00
  ```
- Update the node configuration for the new kubelet version
  ```
  $ kubeadm upgrade node config --kubelet-version v1.12.0
  ```
- Restart the kubelet service
  ```
  $ systemctl restart kubelet
  ```
- Mark the node back to schedulable
  ```
  $ kubectl uncordon node-1
  ```
  
- Upgrade all worker nodes in the same way

  # Backup and Restore Methods
  - Take me to [Video Tutorial](https://kodekloud.com/courses/539883/lectures/9808228)
  
In this section, we will take a look at backup and restore methods

## Backup Candidates
 
## Resource Configuration
- Imperative way
  

- Declarative Way (Preferred approach)
  ```
  apiVersion: v1
  kind: Pod
  metadata:
    name: myapp-pod
    labels:
      app: myapp
      type: front-end
  spec:
    containers:
    - name: nginx-container
      image: nginx
  ```
- A good practice is to store resource configurations on source code repositories like github.


## Backup - Resource Configs

  ```
  $ kubectl get all --all-namespaces -o yaml > all-deploy-services.yaml (only for few resource groups)
  ```

- There are many other resource groups that must be considered. There are tools like **`ARK`** or now called **`Velero`** by Heptio that can do this for you.
  
## Backup - ETCD
- So, instead of backing up resources as before, you may choose to backup the ETCD cluster itself. 
  
  
- You can take a snapshot of the etcd database by using **`etcdctl`** utility snapshot save command.
  ```
  $ ETCDCTL_API=3 etcdctl snapshot save snapshot.db
  ```
- #### With all etcdctl commands specify the cert,key,cacert and endpoint for authentication.
```
$ ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/etcd-server.crt \
  --key=/etc/kubernetes/pki/etcd/etcd-server.key snapshot save /tmp/snapshot.db
```
```
$  ETCDCTL_API=3 etcdctl snapshot status snapshot.db
```
  
## Restore - ETCD
- To restore etcd from the backup at later in time. First stop kube-apiserver service
  ```
  $ service kube-apiserver stop
  ```
- Run the etcdctl snapshot restore command
 ```
 $ ETCDCTL_API=3 etcdctl  --data-dir=/var/lib/etcd-from-backup snapshot restore /opt/snapshot-pre-boot.db
 ```
 ### **or**
 ```
 $ ETCDCTL_API=3 etcdctl snapshot restore --endpoints=https://172.17.0.56:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt /
 --cert=/etc kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --data-dir="/var/lib/etcd-backup" /
--initial-cluster="controlplane=https://172.17.0.56:2380" --name="controlplane" /
--initial-advertise-peer-urls="https://172.17.0 56:2380" --initial-cluster-token="etcd-cluster-1" /opt/snapshot-pre-boot.db
 ```
#### **Update the etcd service**
Update ETCD POD to use the new hostPath directory `/var/lib/etcd-from-backup` by modifying the pod definition file at `/etc/kubernetes/manifests/etcd.yaml`. When this file is updated, the ETCD pod is automatically re-created as this is a static pod placed under the `/etc/kubernetes/manifests` directory.


Update volumes and volume mounts to point to new path

```
  volumes:
  - hostPath:
      path: /var/lib/etcd-from-backup
      type: DirectoryOrCreate
    name: etcd-data
  - hostPath:
      path: /etc/kubernetes/pki/etcd
      type: DirectoryOrCreate
    name: etcd-certs
```
> Note: as the ETCD pod has changed it will automatically restart, and also kube-controller-manager and kube-scheduler. Wait 1-2 to mins for this pods to restart. You can make a `watch "docker ps | grep etcd"` to see when the ETCD pod is restarted.

> Note2: If the etcd pod is not getting `Ready 1/1`, then restart it by `kubectl delete pod -n kube-system etcd-controlplane` and wait 1 minute.


- Reload system configs
  ```
  $ systemctl daemon-reload
  ```
- Restart etcd
  ```
  $ service etcd restart
  ```
- Start the kube-apiserver
  ```
  $ service kube-apiserver start
  ```
- For reference checkout the [tutorial](https://github.com/mmumshad/kubernetes-the-hard-way/blob/master/practice-questions-answers/cluster-maintenance/backup-etcd/etcd-backup-and-restore.md#3-restore-etcd-snapshot-to-a-new-folder)